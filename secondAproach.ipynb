{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"./data/gsn_img_uint8.npy\")\n",
    "mask = np.load(\"./data/gsn_msk_uint8.npy\")\n",
    "print(data.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# functions to show an image\n",
    "def maskshow(mask):\n",
    "    img = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "    img[:] = mask\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def imshow(img):\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax.imshow(img,aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "# print(data[0].shape)\n",
    "# for i in range(10):\n",
    "#     maskshow(mask[i])\n",
    "#     imshow(data[i])\n",
    "\n",
    "def normalize(mask):\n",
    "    return mask/255\n",
    "\n",
    "\n",
    "def imshow_many(imgs):\n",
    "    n = imgs.shape[0]\n",
    "    if n < 20 :\n",
    "        cols = 5\n",
    "        rows = int((n+4)/5)\n",
    "        fig = plt.figure(figsize=(cols * 4, rows * 4))\n",
    "    else :\n",
    "        cols = 10\n",
    "        rows = int((n+9)/10)\n",
    "        fig = plt.figure(figsize=(cols * 2, rows * 2))\n",
    "\n",
    "    for i in range(n):\n",
    "        sub = fig.add_subplot(rows, cols, i + 1)\n",
    "        if(imgs.shape[3] == 1) :\n",
    "            imgs = imgs.reshape((imgs.shape[0], imgs.shape[1], imgs.shape[2]))\n",
    "        sub.imshow(imgs[i], interpolation='nearest')\n",
    "\n",
    "def imshow_masked(imgs, masks):\n",
    "    n = imgs.shape[0]\n",
    "    if n < 20 :\n",
    "        cols = 5\n",
    "        rows = int((n+4)/5)\n",
    "        fig = plt.figure(figsize=(cols * 4, rows * 4))\n",
    "    else :\n",
    "        cols = 10\n",
    "        rows = int((n+9)/10)\n",
    "        fig = plt.figure(figsize=(cols * 2, rows * 2))\n",
    "\n",
    "    for i in range(n):\n",
    "        sub = fig.add_subplot(rows, cols, i + 1)\n",
    "        masks = masks.reshape((masks.shape[0], masks.shape[1], masks.shape[2]))\n",
    "        sub.imshow(imgs[i], interpolation='nearest')\n",
    "        sub.imshow(masks[i], interpolation='nearest', cmap='jet', alpha=0.6)\n",
    "\n",
    "\n",
    "imshow_masked(data[0:5], mask[0:5])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def randomDataAug(data, mask):\n",
    "    def identity(data):\n",
    "        return data\n",
    "\n",
    "    def horizontalSymmetry(data):\n",
    "        newData = np.zeros_like(data)\n",
    "        numRows = data.shape[0]\n",
    "        numCols = data.shape[1]\n",
    "        for i in range(numRows):\n",
    "            for j in range(numCols):\n",
    "                newData[numRows - i  - 1][j] = data[i][j]\n",
    "        return newData\n",
    "\n",
    "    def verticalSymmetry(data):\n",
    "        newData = np.zeros_like(data)\n",
    "        numRows = data.shape[0]\n",
    "        numCols = data.shape[1]\n",
    "        for i in range(numRows):\n",
    "            for j in range(numCols):\n",
    "                newData[i][numCols - j - 1] = data[i][j]\n",
    "        return newData\n",
    "\n",
    "    def diagonalSymmetry1(data):\n",
    "        newData = np.zeros_like(data)\n",
    "        numRows = data.shape[0]\n",
    "        numCols = data.shape[1]\n",
    "        for i in range(numRows):\n",
    "            for j in range(numCols):\n",
    "                newData[numRows - i - 1][numCols - j - 1] = data[j][i]\n",
    "        return newData\n",
    "\n",
    "    def diagonalSymmetry2(data):\n",
    "        newData = np.zeros_like(data)\n",
    "        numRows = data.shape[0]\n",
    "        numCols = data.shape[1]\n",
    "        for i in range(numRows):\n",
    "            for j in range(numCols):\n",
    "                newData[i][j] = data[j][i]\n",
    "        return newData\n",
    "\n",
    "    def rotateRight(data):\n",
    "        newData = np.zeros_like(data)\n",
    "        numRows = data.shape[0]\n",
    "        numCols = data.shape[1]\n",
    "        for i in range(numRows):\n",
    "            for j in range(numCols):\n",
    "                newData[j][numRows - i - 1] = data[i][j]\n",
    "        return newData\n",
    "\n",
    "    def rotateLeft(data):\n",
    "        newData = np.zeros_like(data)\n",
    "        numRows = data.shape[0]\n",
    "        numCols = data.shape[1]\n",
    "        for i in range(numRows):\n",
    "            for j in range(numCols):\n",
    "                newData[numCols - j - 1][i] = data[i][j]\n",
    "        return newData\n",
    "\n",
    "    def rotateTwice(data):\n",
    "        newData = np.zeros_like(data)\n",
    "        numRows = data.shape[0]\n",
    "        numCols = data.shape[1]\n",
    "        for i in range(numRows):\n",
    "            for j in range(numCols):\n",
    "                newData[numCols - j - 1][numRows - i - 1] = data[j][i]\n",
    "        return newData\n",
    "\n",
    "    dataAug = [identity, horizontalSymmetry, verticalSymmetry,\n",
    "               diagonalSymmetry1, diagonalSymmetry2, rotateLeft,\n",
    "               rotateRight, rotateTwice]\n",
    "\n",
    "    f = dataAug[random.randrange(0, 7, 1)]\n",
    "    return f(data), f(mask)\n",
    "\n",
    "def randomDataAugForDataset(data, mask):\n",
    "    assert(data.shape[0] == mask.shape[0])\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i], mask[i] = randomDataAug(data[i], mask[i])\n",
    "    return data, mask\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
    "        \"\"\"\n",
    "        This function creates one contracting block\n",
    "        \"\"\"\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                )\n",
    "        return block\n",
    "\n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "                    )\n",
    "            return  block\n",
    "\n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.BatchNorm2d(mid_channel),\n",
    "                torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.BatchNorm2d(mid_channel),\n",
    "                torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.BatchNorm2d(out_channels),\n",
    "                )\n",
    "        return  block\n",
    "\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UNet, self).__init__()\n",
    "        #Encode\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(128, 256)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.BatchNorm2d(512),\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.BatchNorm2d(512),\n",
    "                            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "                            )\n",
    "        # Decode\n",
    "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
    "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
    "        self.final_layer = self.final_block(128, 64, out_channel)\n",
    "\n",
    "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
    "        \"\"\"\n",
    "        This layer crop the layer from contraction block and concat it with expansive block vector\n",
    "        \"\"\"\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "        # Bottleneck\n",
    "        bottleneck1 = self.bottleneck(encode_pool3)\n",
    "        # Decode\n",
    "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n",
    "        cat_layer2 = self.conv_decode3(decode_block3)\n",
    "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)\n",
    "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n",
    "        final_layer = self.final_layer(decode_block1)\n",
    "        return  final_layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def net():\n",
    "#     unet = UNet(in_channel=3, out_channel=1)\n",
    "#     #out_channel represents number of segments desired\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.SGD(unet.parameters(), lr = 0.01, momentum=0.99)\n",
    "#     optimizer.zero_grad()\n",
    "#     return net, optimizer, criterion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def prepareAndRandDatasets():\n",
    "    data = np.load(\"./data/gsn_img_uint8.npy\")\n",
    "    mask = np.load(\"./data/gsn_msk_uint8.npy\")\n",
    "    # print(data.shape)\n",
    "    # print(mask.shape)\n",
    "    data =  data.transpose(0,3,1,2)\n",
    "    mask = mask.transpose(0,3,1,2)\n",
    "    # print(data.shape)\n",
    "    # print(mask.shape)\n",
    "    # data, mask = randomDataAugForDataset(data, mask)\n",
    "    return data, mask\n",
    "\n",
    "def prepareTestDatasets():\n",
    "    data = np.load(\"./data/test_gsn_image.npy\")\n",
    "    mask = np.load(\"./data/test_gsn_mask.npy\")\n",
    "    data =  data.transpose(0,3,1,2)\n",
    "    mask = mask.transpose(0,3,1,2)\n",
    "    return data, mask\n",
    "\n",
    "prepareAndRandDatasets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "use_gpu = torch.cuda.is_available()\n",
    "from tqdm import tqdm, trange\n",
    "import gc\n",
    "\n",
    "def train_step(inputs, labels, optimizer, criterion, unet, width_out, height_out):\n",
    "    optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    print(\"inputs shape: \", inputs.shape)\n",
    "    outputs = unet(inputs)\n",
    "    # outputs.shape =(batch_size, n_classes, img_cols, img_rows)\n",
    "    outputs = outputs.permute(0, 2, 3, 1)\n",
    "    # outputs.shape =(batch_size, img_cols, img_rows, n_classes)\n",
    "    m = outputs.shape[0]\n",
    "    outputs = outputs.resize(m*width_out*height_out, 1)\n",
    "    labels = labels.resize(m*width_out*height_out)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def get_val_loss(x_val, y_val, width_out, height_out, unet):\n",
    "    x_val = torch.from_numpy(x_val).float()\n",
    "    y_val = torch.from_numpy(y_val).long()\n",
    "    if use_gpu:\n",
    "        x_val = x_val.cuda()\n",
    "        y_val = y_val.cuda()\n",
    "    m = x_val.shape[0]\n",
    "    outputs = unet(x_val)\n",
    "    # outputs.shape =(batch_size, n_classes, img_cols, img_rows)\n",
    "    outputs = outputs.permute(0, 2, 3, 1)\n",
    "    # outputs.shape =(batch_size, img_cols, img_rows, n_classes)\n",
    "    outputs = outputs.resize(m*width_out*height_out, 2)\n",
    "    labels = y_val.resize(m*width_out*height_out)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    return loss.data\n",
    "\n",
    "def train(unet, batch_size, epochs, epoch_lapse, threshold, learning_rate, criterion, optimizer , x_train, y_train, x_val, y_val, width_out, height_out):\n",
    "    epoch_iter = np.ceil(x_train.shape[0] / batch_size).astype(int)\n",
    "    t = trange(epochs, leave=True)\n",
    "    print(\"t if %d\", t)\n",
    "    for _ in t:\n",
    "        x_train, y_train = prepareAndRandDatasets();\n",
    "        total_loss = 0\n",
    "        for i in range(epoch_iter):\n",
    "            batch_train_x = torch.from_numpy(x_train[i * batch_size : (i + 1) * batch_size]).float()\n",
    "            batch_train_y = torch.from_numpy(y_train[i * batch_size : (i + 1) * batch_size]).long()\n",
    "            if use_gpu:\n",
    "                batch_train_x = batch_train_x.cuda()\n",
    "                batch_train_y = batch_train_y.cuda()\n",
    "            batch_loss = train_step(batch_train_x , batch_train_y, optimizer, criterion, unet, width_out, height_out)\n",
    "            total_loss += batch_loss\n",
    "        if (_+1) % epoch_lapse == 0:\n",
    "            val_loss = get_val_loss(x_val, y_val, width_out, height_out, unet)\n",
    "            print(\"Total loss in epoch %f : %f and validation loss : %f\" %(_+1, total_loss, val_loss))\n",
    "    gc.collect()\n",
    "\n",
    "def plot_examples(unet, datax, datay, num_examples=3):\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(18,4*num_examples))\n",
    "    m = datax.shape[0]\n",
    "    for row_num in range(num_examples):\n",
    "        image_indx = np.random.randint(m)\n",
    "        image_arr = unet(torch.from_numpy(datax[image_indx:image_indx+1]).float().cuda()).squeeze(0).detach().cpu().numpy()\n",
    "        ax[row_num][0].imshow(np.transpose(datax[image_indx], (1,2,0))[:,:,0])\n",
    "        ax[row_num][1].imshow(np.transpose(image_arr, (1,2,0))[:,:,0])\n",
    "        ax[row_num][2].imshow(image_arr.argmax(0))\n",
    "        ax[row_num][3].imshow(np.transpose(datay[image_indx], (1,2,0))[:,:,0])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    width_in = 128\n",
    "    height_in = 128\n",
    "    width_out = 128\n",
    "    height_out = 128\n",
    "    PATH = './unet.pt'\n",
    "    x_train, y_train = prepareAndRandDatasets()\n",
    "    x_val, y_val = prepareTestDatasets()\n",
    "    print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "    batch_size = 1\n",
    "    epochs = 1\n",
    "    epoch_lapse = 10\n",
    "    threshold = 0.5\n",
    "    learning_rate = 0.01\n",
    "    unet = UNet(in_channel=3,out_channel=1)\n",
    "    if use_gpu:\n",
    "        unet = unet.cuda()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(unet.parameters(), lr = 0.01, momentum=0.99)\n",
    "\n",
    "    train(unet, batch_size, epochs, epoch_lapse, threshold, learning_rate, criterion, optimizer, x_train, y_train, x_val, y_val, width_out, height_out)\n",
    "\n",
    "    print(unet.eval())\n",
    "    plot_examples(unet, x_train, y_train)\n",
    "    plot_examples(unet, x_val, y_val)\n",
    "    return unet\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "unet = main()\n",
    "torch.save(unet.state_dict(), \"./u-net\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}